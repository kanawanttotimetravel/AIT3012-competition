{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from numpy import trapz\n",
    "from scipy import signal, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_eeg_signal(data, chunk_seconds=10, overlap_seconds=5, sampling_rate=250):\n",
    "    \"\"\"\n",
    "    Chunk EEG signal data with overlapping windows.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Calculate number of samples per chunk and overlap\n",
    "    samples_per_chunk = chunk_seconds * sampling_rate\n",
    "    overlap_samples = overlap_seconds * sampling_rate\n",
    "    stride = samples_per_chunk - overlap_samples\n",
    "    \n",
    "    # Get total number of samples and channels\n",
    "    n_channels, n_samples = data.shape\n",
    "    \n",
    "    # Calculate number of complete chunks we can make\n",
    "    n_chunks = (n_samples - samples_per_chunk) // stride + 1\n",
    "    \n",
    "    # Initialize arrays to store chunks and labels\n",
    "    chunks = np.zeros((n_chunks, n_channels, samples_per_chunk))\n",
    "    \n",
    "    # Create chunks\n",
    "    for i in range(n_chunks):\n",
    "        start_idx = i * stride\n",
    "        end_idx = start_idx + samples_per_chunk\n",
    "        \n",
    "        # Store the chunk\n",
    "        chunks[i] = data[:, start_idx:end_idx]\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eeg_chunk(chunk_data, sampling_rate=250):\n",
    "\t\"\"\"\n",
    "\tProcess a single EEG chunk into features.\n",
    "\t\n",
    "\tParameters:\n",
    "\t-----------\n",
    "\tchunk_data : numpy.ndarray\n",
    "\t\tEEG data of shape (n_channels, n_samples)\n",
    "\tsampling_rate : int\n",
    "\t\tSampling rate in Hz\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t--------\n",
    "\tnumpy.ndarray\n",
    "\t\tFeatures array of shape (n_channels, n_features)\n",
    "\t\"\"\"\n",
    "\tn_channels = chunk_data.shape[0]\n",
    "\tn_features = 20  # Increased number of features\n",
    "\tfeatures = np.zeros((n_channels, n_features))\n",
    "\t\n",
    "\t# Define frequency bands\n",
    "\tbands = {\n",
    "\t\t'delta': (0.5, 4),\n",
    "\t\t'theta': (4, 8),\n",
    "\t\t'alpha': (8, 13),\n",
    "\t\t'beta': (13, 30),\n",
    "\t\t'gamma': (30, 45)\n",
    "\t}\n",
    "\t\n",
    "\tfor channel in range(n_channels):\n",
    "\t\tsignal_channel = chunk_data[channel]\n",
    "\t\tfeature_idx = 0\n",
    "\t\t\n",
    "\t\t# 1. Compute power spectral density with better frequency resolution\n",
    "\t\tnperseg = min(signal_channel.shape[0], 2 * sampling_rate)  # 2-second windows\n",
    "\t\tfreqs, psd = signal.welch(signal_channel, sampling_rate, nperseg=nperseg, \n",
    "\t\t\t\t\twindow='hann', noverlap=nperseg//2)\n",
    "\t\t\n",
    "\t\t# 2. Calculate band powers and ratios\n",
    "\t\tband_powers = {}\n",
    "\t\ttotal_power = trapz(y=psd, x=freqs)\n",
    "\t\t\n",
    "\t\tfor band_name, (low, high) in bands.items():\n",
    "\t\t\tidx = np.logical_and(freqs >= low, freqs <= high)\n",
    "\t\t\tband_power = trapz(y=psd[idx], x=freqs[idx])\n",
    "\t\t\tband_powers[band_name] = band_power / total_power\n",
    "\t\t\n",
    "\t\t# 3. Time domain features\n",
    "\t\tfeatures[channel, feature_idx] = np.std(signal_channel)  # Standard deviation\n",
    "\t\tfeature_idx += 1\n",
    "\t\t\n",
    "\t\t# Zero crossing rate\n",
    "\t\tfeatures[channel, feature_idx] = len(np.where(np.diff(np.signbit(signal_channel)))[0]) / len(signal_channel)\n",
    "\t\tfeature_idx += 1\n",
    "\t\t\n",
    "\t\t# Line length (signal complexity)\n",
    "\t\tfeatures[channel, feature_idx] = np.sum(np.abs(np.diff(signal_channel)))\n",
    "\t\tfeature_idx += 1\n",
    "\t\t\n",
    "\t\t# 4. Frequency domain features\n",
    "\t\tfor band_power in band_powers.values():\n",
    "\t\t\tfeatures[channel, feature_idx] = band_power\n",
    "\t\t\tfeature_idx += 1\n",
    "\t\t\t\n",
    "\t\t# Add frequency band ratios\n",
    "\t\tfeatures[channel, feature_idx] = band_powers['theta'] / band_powers['beta']  # theta/beta ratio\n",
    "\t\tfeature_idx += 1\n",
    "\t\t\n",
    "\t\tfeatures[channel, feature_idx] = band_powers['alpha'] / band_powers['beta']  # alpha/beta ratio\n",
    "\t\tfeature_idx += 1\n",
    "\t\t\n",
    "\t\t# Spectral edge frequency (95%)\n",
    "\t\tcumsum = np.cumsum(psd)\n",
    "\t\tfeatures[channel, feature_idx] = freqs[np.where(cumsum >= 0.95 * cumsum[-1])[0][0]]\n",
    "\t\tfeature_idx += 1\n",
    "\t\t\n",
    "\t\t# 5. Statistical features\n",
    "\t\tfeatures[channel, feature_idx] = stats.kurtosis(signal_channel)\n",
    "\t\tfeature_idx += 1\n",
    "\t\t\n",
    "\t\tfeatures[channel, feature_idx] = stats.skew(signal_channel)  # Add skewness\n",
    "\t\tfeature_idx += 1\n",
    "\t\t\n",
    "\t\t# 6. Hjorth parameters (improved calculation)\n",
    "\t\tdiff1 = np.diff(signal_channel)\n",
    "\t\tdiff2 = np.diff(diff1)\n",
    "\t\t\n",
    "\t\tmobility = np.sqrt(np.var(diff1) / np.var(signal_channel))\n",
    "\t\tfeatures[channel, feature_idx] = mobility\n",
    "\t\tfeature_idx += 1\n",
    "\t\t\n",
    "\t\tcomplexity = np.sqrt(np.var(diff2) * np.var(signal_channel)) / np.var(diff1)\n",
    "\t\tfeatures[channel, feature_idx] = complexity\n",
    "\t\tfeature_idx += 1\n",
    "\t\t\n",
    "\t\t# 8. Peak frequency per band\n",
    "\t\tfor band_name, (low, high) in bands.items():\n",
    "\t\t\tidx = np.logical_and(freqs >= low, freqs <= high)\n",
    "\t\t\tif np.any(idx):\n",
    "\t\t\t\tpeak_freq = freqs[idx][np.argmax(psd[idx])]\n",
    "\t\t\t\tfeatures[channel, feature_idx] = peak_freq\n",
    "\t\t\t\tfeature_idx += 1\n",
    "\t\n",
    "\treturn features\n",
    "\n",
    "def process_all_chunks(chunks_data, sampling_rate=250):\n",
    "\t\"\"\"\n",
    "\tProcess multiple EEG chunks into features.\n",
    "\t\n",
    "\tParameters:\n",
    "\t-----------\n",
    "\tchunks_data : numpy.ndarray\n",
    "\t\tEEG chunks of shape (n_chunks, n_channels, n_samples)\n",
    "\tsampling_rate : int\n",
    "\t\tSampling rate in Hz (default: 250)\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t--------\n",
    "\tnumpy.ndarray\n",
    "\t\tFeatures array of shape (n_chunks, n_channels, n_features)\n",
    "\t\"\"\"\n",
    "\tn_chunks = chunks_data.shape[0]\n",
    "\tn_channels = chunks_data.shape[1]\n",
    "\tn_features = 20  # Number of features per channel\n",
    "\t\n",
    "\t# Initialize array for all features\n",
    "\tall_features = np.zeros((n_chunks, n_channels, n_features))\n",
    "\t\n",
    "\t# Process each chunk\n",
    "\tfor i in range(n_chunks):\n",
    "\t\tall_features[i] = process_eeg_chunk(chunks_data[i], sampling_rate)\n",
    "\t\n",
    "\treturn all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_elim(data):\n",
    "\t# Detect and delete zeros in subarrays of length >= 250\n",
    "\tchannel_0 = data[0, :]\n",
    "\tzero_start = None\n",
    "\tindices_to_delete = []\n",
    "\n",
    "\tfor i, value in enumerate(channel_0):\n",
    "\t\tif value == 0:\n",
    "\t\t\tif zero_start is None:\n",
    "\t\t\t\tzero_start = i  # Mark the start of a zero sequence\n",
    "\t\telse:\n",
    "\t\t\tif zero_start is not None:\n",
    "\t\t\t\t# End of a zero sequence\n",
    "\t\t\t\tzero_length = i - zero_start\n",
    "\t\t\t\tif zero_length >= 250:\n",
    "\t\t\t\t\tindices_to_delete.extend(range(zero_start, i))\n",
    "\t\t\t\tzero_start = None\n",
    "\n",
    "\t# Handle case where the array ends with a long zero sequence\n",
    "\tif zero_start is not None:\n",
    "\t\tzero_length = len(channel_0) - zero_start\n",
    "\t\tif zero_length >= 250:\n",
    "\t\t\tindices_to_delete.extend(range(zero_start + 1, len(channel_0)))\n",
    "\n",
    "\t# Delete indices from all 52 channels\n",
    "\tif indices_to_delete:\n",
    "\t\tdata = np.delete(data, indices_to_delete, axis=1)\n",
    "\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(id):\n",
    "\tdata = []\n",
    "\twith h5py.File('data_250hz.h5', 'r') as f:\n",
    "\t\tfor i in range(52):\n",
    "\t\t\tparcel = f[id + '/parcel_' + str(i)][:]\n",
    "\t\t\tparcel = np.squeeze(parcel)\n",
    "\t\t\tdata.append(parcel)\n",
    "\tdata = np.array(data)\n",
    "\tdata = zero_elim(data)\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [27:31<00:00, 13.76s/it]\n"
     ]
    }
   ],
   "source": [
    "train_data = {}\n",
    "for id in tqdm(y_train['id']):\n",
    "\tdata = get_data(id)\n",
    "\tchunked_data = chunk_eeg_signal(data)\n",
    "\tall_features = process_all_chunks(chunked_data)\n",
    "\ttrain_data[id] = all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dict\n",
    "np.save('train_data.npy', train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [04:32<00:00,  2.27s/it]\n"
     ]
    }
   ],
   "source": [
    "train_all_data = []\n",
    "for id in tqdm(y_train['id']):\n",
    "\ttrain_data = get_data(id)\n",
    "\tall_features = process_eeg_chunk(train_data)\n",
    "\ttrain_all_data.append(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 52, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_data = np.array(train_all_data)\n",
    "train_all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_all_data.npy', train_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:37<00:00,  2.43s/it]\n"
     ]
    }
   ],
   "source": [
    "test_all_data = []\n",
    "for id in tqdm(y_test['id']):\n",
    "\ttest_data = get_data(id)\n",
    "\ttest_features = process_eeg_chunk(test_data)\n",
    "\ttest_all_data.append(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 52, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all_data = np.array(test_all_data)\n",
    "test_all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features\n",
    "np.save('test_features.npy', test_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [08:18<00:00, 12.45s/it]\n"
     ]
    }
   ],
   "source": [
    "test_chunk = {}\n",
    "for id in tqdm(y_test['id']):\n",
    "\ttest_data = get_data(id)\n",
    "\ttest_chunked_data = chunk_eeg_signal(test_data)\n",
    "\ttest_features = process_all_chunks(test_chunked_data)\n",
    "\ttest_chunk[id] = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test_data.npy', test_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
